var tipuesearch = {"pages":[{"title":"PrÃ©diction des prochaines musiques hits (partie 1)","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Des milliers de chansons voient le jour tous les ans dans le monde. Certaines connaissent de vrais succÃ¨s dans l'industrie musicale ; d'autres moins. Il est un fait que rÃ©ussir dans cette industrie demeure une tÃ¢che difficile. Investir dans la production d'une chanson requiert des activitÃ©s diversifiÃ©es et peuvent consommer beaucoup de ressources. Jusque-lÃ , il n'y a aucun outil automatique qui permettrait aux artistes et aux producteurs d'Ã©valuer que la chanson qu'ils vont publier sera un Â« hit musical Â». Dans cet article, nous chercherons Ã  comprendre ce qui caractÃ©rise une chanson populaire, et plus prÃ©cisÃ©ment comment il serait possible de prÃ©dire la popularitÃ© d'une chanson en nous basant uniquement sur ces caractÃ©ristiques d'audio et sur le profil de l'artiste. Pour rÃ©pondre Ã  cette question, nous allons construire un modÃ¨le-classeur de machine learning pouvant classer une chanson en hit ou non-hit. Bien que des facteurs sociaux comme le contexte dans lequel la chanson a Ã©tÃ© diffusÃ©e, la dÃ©mographie de ses auditeurs et l'effectivitÃ© de sa campagne de marketing peuvent tout aussi bien jouer un rÃ´le important dans sa viralitÃ©, nous Ã©mettons l'hypothÃ¨se que les caractÃ©ristiques inhÃ©rentes Ã  une chanson, tels que l'artiste qui l'interprÃ¨te, sa durÃ©e, ses caractÃ©ristiques d'audio peuvent Ãªtre corrÃ©lÃ©s et Ã©galement rÃ©vÃ©lateur de sa viralitÃ©. Construction du jeu de donnÃ©es Plus nous avons de donnÃ©es pertinentes, mieux sera la capacitÃ© prÃ©dictive de notre modÃ¨le. Nous n'avons pas pu disposer d'un dataset venant d'une seule et unique source qui comporterait toutes les variables. Alors, il nous a fallu recourir aux techniques de Â« data enrichment Â». Notre jeu de donnÃ©es a Ã©tÃ© construit Ã  partir de trois (3) sources de donnÃ©es en suivant la mÃ©thode suivante : Nous avons utilisÃ© la page WikipÃ©dia de Billboard Year-End Hot 100 pour recueillir les musiques les plus populaires (hits) datant de 2010 Ã  2019. On a utilisÃ© le web scrapping pour accomplir cette tÃ¢che. Ensuite, nous avons utilisÃ© le package Spotipy pour rÃ©cupÃ©rer les caractÃ©ristiques relatives, d'une part, Ã  l'audio telles que la dansabilitÃ©, la vivacitÃ©, l'instrumentalitÃ©, etc; et d'autre part, Ã  l'artiste comme la popularitÃ©, le nombre de followers etc. pour des chansons hits provenant du Billboard Year-End Hot 100 et d'autres chansons non-hits de la mÃªme pÃ©riode. Et enfin, Genius sera utilisÃ© principalement pour la rÃ©cupÃ©ration des paroles des chansons que nous avons recueillies. Une musique de notre dataset est considÃ©rÃ©e comme un Â« hit Â» si elle a fait partie du classement du Billboard Year-End Hot 100 au moins une fois pendant l'une des annÃ©es sur la pÃ©riode considÃ©rÃ©e. En d'autres termes, notre modÃ¨le aura pour mission de prÃ©dire si une chanson fera partie de la liste des 100 musiques les plus populaires de Billboard ou non. Notre jeu de donnÃ©es est construit Ã  partir d'un programme Python, utilisant des packages parmi les plus utilisÃ©s en data science. Tous les codes du projet sont accessibles ici . Outils utilisÃ©s: Le package spotipy pour accÃ©der aux donnÃ©es de la plateforme musicale de Spotify seaborn et matplotlib pour la visualisation des donnÃ©es pandas et numpy pour l'analyse des donnÃ©es La librairie scikit-learn pour la construction du modÃ¨le de machine learning Les variables Spotify est l'une des plus grandes plateformes de streaming dans le monde. A l'instar de Twitter ou Facebook, elle fournit une API (Application Programming Interface) pour que les developpeurs puissent interagir avec son immense base de donnÃ©es musicale. Via des endpoints de cet API, j'ai pu rÃ©colter des donnÃ©es pour plus de 22 000 chansons; chaque chanson Ã©tant caracterisÃ©e par environ une vingtaine de variables. Les variables retournÃ©es par l'API sont aussi riches en information que variÃ©es. Toutefois, j'ai selectionnÃ© uniquement celles qui sont jugÃ©es pertinentes pour le travail. Ensuite, elles ont Ã©tÃ© transformÃ©es via les techniques de feature engineering afin de prÃ©parer le jeu de donnÃ©es au mieux pour l'entraÃ®nement du modÃ¨le. Vous trouverez ci-dessous le nom et la description de chaque variable utilisÃ©e. Les variables relatives Ã  l'artiste nom_artiste : Nom de l'artiste principal de la chanson. PopularitÃ© : La popularitÃ© de l'artiste sur Spotify. La valeur sera comprise entre 0 et 100, 100 Ã©tant le plus populaire. Nous pensons que plus un artiste est populaire, plus une chanson sur laquelle il pose sa voix est susceptible d'Ãªtre virale. Followers : Nombre total de followers sur Spotify. Les variables relatives Ã  la chanson Date de sortie : Date Ã  laquelle la chanson a Ã©tÃ© diffusÃ©e pour la premiÃ¨re fois. MarchÃ© disponible : Nombre de pays dans lequel la chanson peut Ãªtre jouÃ©e. DurÃ©e : La durÃ©e de la chanson en millisecondes. Acoustique : Une mesure de confiance de 0.0 Ã  1.0 indiquant si la chanson est acoustique. 1.0 reprÃ©sente une confiance Ã©levÃ©e que la chanson est acoustique. DansabilitÃ© : La dansabilitÃ© dÃ©crit Ã  quel point une chanson est adaptÃ©e Ã  la danse sur la base d'une combinaison d'Ã©lÃ©ments musicaux, notamment le tempo, la stabilitÃ© du rythme, la force du rythme et la rÃ©gularitÃ© globale. Une valeur de 0.0 est la moins dansante et 1.0 est la plus dansante. Energie : L'Ã©nergie est une mesure de 0.0 Ã  1.0 et reprÃ©sente une mesure perceptuelle de l'intensitÃ© et de l'activitÃ©. En rÃ¨gle gÃ©nÃ©rale, les chansons Ã©nergiques sont rapides, sonores et bruyantes. InstrumentalitÃ© : Celle-ci prÃ©dit si une chanson ne contient pas de voix. Les sons Â«OohÂ» et Â«aahÂ» sont traitÃ©s comme instrumentaux dans ce contexte. Les morceaux de rap ou de mots parlÃ©s sont clairement Â«vocauxÂ». Plus la valeur instrumentale est proche de 1.0, plus la piste ne contient aucun contenu vocal. Les valeurs supÃ©rieures Ã  0.5 sont censÃ©es reprÃ©senter des chansons instrumentales, mais la confiance est plus Ã©levÃ©e lorsque la valeur approche de 1.0. VivacitÃ© : DÃ©tecte la prÃ©sence d'un public dans l'enregistrement. Des valeurs de vivacitÃ© plus Ã©levÃ©es reprÃ©sentent une probabilitÃ© accrue que la chanson ait Ã©tÃ© jouÃ©e en direct. Une valeur supÃ©rieure Ã  0.8 offre une forte probabilitÃ© que la chanson soit en direct. IntensitÃ© : L'intensitÃ© globale d'une chanson en dÃ©cibels (dB). Les valeurs d'intensitÃ© sont moyennÃ©es sur toute la chanson et sont utiles pour comparer l'intensitÃ© relative des chansons. L'intensitÃ© sonore est la qualitÃ© d'un son qui est le principal corrÃ©lat psychologique de la force physique (amplitude). Les valeurs varient entre -60 et 0 db. Eloquence : L'Ã©loqunece dÃ©tecte la prÃ©sence de mots prononcÃ©s dans une chanson. Plus l'enregistrement est exclusivement vocal (par exemple, talk-show, livre audio, poÃ©sie), plus la valeur d'attribut est proche de 1.0. Les valeurs supÃ©rieures Ã  0.66 dÃ©crivent des chansons qui sont probablement entiÃ¨rement constituÃ©es de mots prononcÃ©s. Les valeurs comprises entre 0.33 et 0.66 dÃ©crivent des pistes qui peuvent contenir Ã  la fois de la musique et de la parole, soit en sections, soit en couches, y compris des cas comme la musique rap. Les valeurs infÃ©rieures Ã  0.33 reprÃ©sentent trÃ¨s probablement de la musique et d'autres pistes non vocales. Valence : Une mesure de 0.0 Ã  1.0 dÃ©crivant la positivitÃ© musicale vÃ©hiculÃ©e par une chanson. Les chansons avec une valence Ã©levÃ©e semblent plus positives (par exemple, joyeuses, gaies, euphoriques), tandis que les chansons avec une valence basse semblent plus nÃ©gatives (par exemple tristes, dÃ©primÃ©es, en colÃ¨re). Tempo : Le tempo global estimÃ© d'une chanson en battements par minute (BPM). Dans la terminologie musicale, le tempo est la vitesse ou le rythme d'une piÃ¨ce donnÃ©e et dÃ©coule directement de la durÃ©e moyenne des temps. hit : Variable dichotomique mesurant si une chanson est hit ou non. Elle prend la valeur de 1 si la chanson est hit, 0 sinon. C'est notre variable dÃ©pendante, c'est-Ã -dire celle que l'on cherchera Ã  prÃ©dire pour une chanson donnÃ©e. featuring : Variable dÃ©pendante dichotomique mesurant s'il y a un ou plusieurs artistes invitÃ©s sur une chanson. mois : Mois de sortie de la chanson. jour_sem : Jour de la semaine durant lequel la chanson a Ã©tÃ© diffusÃ©e. jour : Jour de sortie de la chanson. Certaines de ces variables sont utilisÃ©es uniquement pour l'analyse, d'autres participent Ã  toutes les Ã©tapes du pipeline. A prÃ©sent, jetons un coup d'oeil sur la dimension de notre jeu de donnÃ©es. In [2]: df . shape Out[2]: (19182, 24) AprÃ¨s avoir choisi les variables disponibles jugÃ©es pertinentes pour le modÃ¨le, supprimÃ© les observations contenant des valeurs manquantes et les duplications, notre jeu est rÃ©duit Ã  19 120 observations contenant 24 variables chacune. Les 5 premiÃ¨res observations de notre jeu sont les suivantes: In [3]: df . head ( n = 5 ) Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } nom_artiste pop_artiste tot_followers nom_chanson marche_disp date_sortie pop_chanson acoustique dansabilite duree ... eloquence tempo time_signature valence hit featuring search mois_sortie jour_sortie jour_sem_sortie 0 Kesha 81 5470072 TiK ToK 79 2010-01-01 79 0.09910 0.755 199693 ... 0.1420 120.028 4 0.714 1 0 Kesha TiK ToK 1 1 4 1 Lady Antebellum 74 2933375 Need You Now 78 2010-01-01 69 0.09270 0.587 277573 ... 0.0303 107.943 4 0.231 1 0 Lady Antebellum Need You Now 1 1 4 2 Train 77 3249275 Hey, Soul Sister 79 2010-12-01 82 0.18500 0.673 216773 ... 0.0431 97.012 4 0.795 1 0 Train Hey, Soul Sister 12 1 2 3 Katy Perry 87 15347727 California Gurls 79 2012-03-12 72 0.00446 0.791 234653 ... 0.0569 125.014 4 0.425 1 0 Katy Perry California Gurls 3 12 0 4 Usher 82 7654666 OMG (feat. will.i.am) 79 2010-03-30 71 0.19800 0.781 269493 ... 0.0332 129.998 4 0.326 1 1 Usher OMG (feat. will.i.am) 3 30 1 5 rows Ã 24 columns Visualisation In [4]: % matplotlib inline from matplotlib import pyplot as plt fig = plt . figure ( figsize = ( 16 , 8 )) ax = fig . add_axes ([ 0 , 0 , 1 , 1 ]) pop = [ 'non-hit' , 'hit' ] pop_count = list ( df [ 'hit' ] . value_counts ()) ax . bar ( pop , pop_count , color = '#293484' ) for i , v in enumerate ( pop_count ): ax . text ( i -. 05 , v + 100 , pop_count [ i ], fontsize = 12 , color = 'black' ) plt . title ( 'Distribution des nombres de chansons \\n suivant les modalitÃ©s de la variable hit.' ) plt . ylabel ( 'nombre_de_chansons' ) plt . xlabel ( 'classe' ) plt . show () La distribution de la variable dÃ©pendante hit est telle que seulement 902 chansons du jeu de donnÃ©es sont hits, alors que 18280 ne le sont pas. Il y a lieu de contraster un dÃ©sÃ©quilibre flagrant au sein de notre variable d'intÃ©rÃªt. On rÃ¨glera ce souci plus tard avant de passer Ã  la phase d'entraÃ®nement de notre modÃ¨le. In [5]: fig ,( ax1 , ax2 , ax3 ) = plt . subplots ( 1 , 3 , figsize = ( 18 , 8 )) fig . suptitle ( 'Date de sortie des musiques hits' ) ax1 . set_title ( 'Mois' ) ax1 . hist ( df [ df [ 'hit' ] == 1 ][ 'mois_sortie' ], bins = 30 , color = 'blue' ) ax2 . set_title ( 'Jour de la semaine' ) ax2 . hist ( df [ df [ 'hit' ] == 1 ][ 'jour_sem_sortie' ], bins = 14 , color = 'red' ) ax3 . set_title ( 'Jour' ) ax3 . hist ( df [ df [ 'hit' ] == 1 ][ 'jour_sortie' ], bins = 62 , color = 'blue' ) plt . show () A la lumiÃ¨re du graphique ci-dessus, janvier est le mois durant lequel plus de musiques hits sont sorties; juillet Ã©tant le mois le moins sollicitÃ©. On remarque aussi que la majoritÃ© des hits de la pÃ©riode sont sortis le 4Ã¨me jour de la semaine; soit jeudi. Enfin le premier jour du mois est largement plus utilisÃ© pour publier une chanson. Fort de ce constat, on pourrait dÃ©duire que publier une chanson le premier janvier, c'est probablement un pas vers l'optimisation des chances de sa viralitÃ©. On doit tout de mÃªme Ãªtre prudent: corrÃ©lation n'est pas causalitÃ©. Il faudrait pousser notre analyse plus en profondeur afin d'Ãªtre plus prÃ©cis dans cette conclusion. Quels sont les artistes les plus populaires sur la pÃ©riode considÃ©rÃ©e? In [6]: plt . figure ( figsize = ( 16 , 8 )) artistes = df [ df [ 'hit' ] == 1 ][ 'nom_artiste' ] . value_counts ()[: 20 ] artistes . plot ( kind = \"bar\" , color = 'blue' ) plt . title ( \"Les artistes avec le plus de musiques hits\" ) plt . show () Sans surprise aucune, les artistes comme Drake, Rihanna et Taylor Swift ont enregistrÃ© plus de musiques hits que quiconque autre artiste sur la pÃ©riode. Ceci Ã©tant dit, il est plausible de croire qu'une chanson a plus de chances d'Ãªtre virale si elle contient la voix de l'un de ces artistes. In [7]: plt . figure ( figsize = ( 16 , 8 )) plt . hist ( df [ df [ 'hit' ] == 1 ][ 'pop_artiste' ], bins = 100 , density = True , alpha = 0.5 , label = \"hit\" , color = 'blue' ) plt . hist ( df [ df [ 'hit' ] == 0 ][ 'pop_artiste' ], bins = 100 , density = True , alpha = 0.5 , label = \"non-hit\" , color = 'red' ) plt . title ( \"PopularitÃ© des artistes\" ) plt . legend () plt . show () Les deux distributions sont assymÃ©triques Ã  droite. Cependant, l'assymÃ©trie de la distribution des musiques hits est plus prononcÃ©e. 75 % des musiques non-hits ont des artistes dont la popularitÃ© est infÃ©rieure Ã  82, alors que seulement la popularitÃ© des artistes de 50 % des musiques hits est infÃ©rieure Ã  ce nombre. pop_artiste pourrait Ãªtre une variable explicative importante dans la prÃ©diction de la classe d'une chanson. Quid de la rÃ©partition des variables d'audio au sein des deux catÃ©gories? In [8]: import numpy as np from matplotlib import pyplot as plt features_hit = df . loc [ df [ 'hit' ] == 1 ,[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'eloquence' , 'valence' ]] features_non_hit = df . loc [ df [ 'hit' ] == 0 ,[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'eloquence' , 'valence' ]] N = len ( features_hit . mean ()) #Liste des nombre de variables ind = np . arange ( N ) width = 0.25 #diagrame en batons avec la liste des musiques hits plt . barh ( ind , features_hit . mean () , width , label = 'hits' , color = 'blue' ) #diagrame en batons avec la liste des musiques non hits plt . barh ( ind + width , features_non_hit . mean (), width , label = 'non-hits' , color = 'red' ) #X- label plt . xlabel ( 'Moyenne' , fontsize = 12 ) # Title plt . title ( \"Distribution des valeurs moyennes \\n des caractÃ©ristiques d'audio des chansons.\" ) #Vertical ticks plt . yticks ( ind + width / 2 , ( list ( features_non_hit )[:]), fontsize = 12 ) #legend plt . legend ( loc = 'best' ) # Figure size plt . rcParams [ 'figure.figsize' ] = ( 16 , 8 ) # Set style plt . style . use ( \"ggplot\" ) plt . show () Les variables prÃ©dominantes au sein des deux catÃ©gories sont les mÃªmes : energie , dansabilite et valence . La seule diffÃ©rence est que les valeurs moyennÃ©es de ces variables sont plus Ã©levÃ©es pour la catÃ©gorie des chansons hits. Ceci atteste que les musiques hits sont plus rapides et sonores. Elles sont plus adaptÃ©es Ã  la danse et sont plus enclines Ã  inspirer la joie, la gaitÃ©, l'euphorie. L'approche de machine learning Jusque-lÃ , nous avons pu dÃ©couvrir quelques insights interÃ©ssants Ã  propos des donnÃ©es. Afin d'Ã©courter cet article, passons directement Ã  la partie concernant l'algorithme de machine learning que nous allons utiliser. Nous allons construire un modÃ¨le afin de prÃ©dire la classe, hit ou non-hit, qu'une musique est la plus susceptible d'appartenir en nous basant sur un ensemble de variables explicatives, comme expliquÃ© au dÃ©but de cet article. Il est important de garder en tÃªte que nous voulons un modÃ¨le qui soit le plus performant possible. Nous allons utiliser l'algorithme de classification de LightGBM . Pourquoi? [J'ai dÃ©couvert ce framework rÃ©cemment alors que je participais Ã  une compÃ©tition sur Kaggle.] LightGBM fournit des rÃ©sultats robustes et il est largement utilisÃ© dans de nombreuses solutions gagnantes de concours de machine learning. En guise d'expliquer comment l'algorithme fonctionne, nous nous contenterons de mentionner que nous allons utiliser une approche de machine learning supervisÃ© et que LightGBM est un framework de gradient boosting qui utilise des algorithmes d'apprentissage basÃ©s sur des arbres. Il est conÃ§u pour Ãªtre distribuÃ© et efficient avec les avantages suivants: Vitesse d'entraÃ®nement plus rapide et efficacitÃ© plus Ã©levÃ©e. Utilisation rÃ©duite de la mÃ©moire. Meilleure prÃ©cision. Prise en charge de l'apprentissage parallÃ¨le et GPU. Capable de gÃ©rer des donnÃ©es Ã  grande Ã©chelle. Suppression de variables La premiÃ¨re Ã©tape dans la prÃ©paration de notre jeu de donnÃ©es pour l'entrainement du modÃ¨le est de nous assurer que toutes les colonnes sont de valeurs numÃ©riques. C'est en ce sens que nous avons supprimÃ© les variables comme nom_chanson, search, nom_artiste, date_sortie, jour_sortie, jour_sem_sortie et mois_sortie. In [9]: df . drop ([ 'nom_chanson' , 'search' , 'nom_artiste' , 'date_sortie' , 'jour_sem_sortie' , 'jour_sortie' , 'mois_sortie' , 'time_signature' ], axis = 1 , inplace = True ) Feature engineering A ce stade, nous avons eu recours Ã  plusieurs techniques afin d'optimiser notre jeu de donnÃ©es. En rÃ©alitÃ©, nous en avons dÃ©jÃ  appliquÃ© quelques-unes au dÃ©but lorsqu'il Ã©tait question de gÃ©rer les valeurs manquantes, les duplications, l'extraction des dates, One-Hot-Encoding, etc. A prÃ©sent nous allons appliquer la technique dite scaling sur quelques variables du jeu. Cette technique a la vertu de mettre toutes les variables numÃ©riques quantitatives sur une mÃªme base comparable. Bien, voyons Ã  quoi ressemble notre jeu maintenant. In [10]: from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler () df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'duree' , 'pop_chanson' ]] = scaler . fit_transform ( df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'duree' , 'pop_chanson' ]]) In [11]: df . head ( n = 2 ) Out[11]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } pop_artiste tot_followers marche_disp pop_chanson acoustique dansabilite duree energie instrumentalite vivacite intensite eloquence tempo valence hit featuring 0 0.81 0.084919 1.000000 0.822917 0.099498 0.771195 0.031525 0.836997 0.000000 0.291919 0.933029 0.149474 0.545336 0.721212 1 0 1 0.74 0.045538 0.987179 0.718750 0.093072 0.599591 0.046020 0.621992 0.000636 0.202020 0.882599 0.031895 0.490429 0.233333 1 0 Veuillez remarquer que toutes les variables quantitatives indÃ©pendantes sont comprises dans l'intervalle [0,1]. Dans la rÃ©alitÃ©, cela ne fait aucun sens qu'une variable telle que tot_followers , par exemple, contienne des valeurs entre 0 et 1. Mais du point de vue de l'algorithme, cela a tout son sens car c'est par ce procÃ©dÃ© que les variables deviennent comparables. Les algorithmes de machine learning fonctionnent mieux lorsque les variables indÃ©pendantes sont relativement Ã  une Ã©chelle similaire et proches de la distribution normale. SurÃ©chantillonage des donnÃ©es Rappelons-nous qu'au regard de la variable dÃ©pendante, notre jeu de donnÃ©es est trÃ¨s dÃ©sÃ©quilibrÃ©. La catÃ©gorie hit est sous-reprÃ©sentÃ©e par rapport Ã  la classe non-hit. Pour y remÃ©dier, nous allons recourir Ã  la technique dite SMOTE. SMOTE (Synthetic Minority Over-Sampling TEchnique) est une technique utilisÃ©e pour traiter des ensembles de donnÃ©es dÃ©sÃ©quilibrÃ©es. Introduite pour la premiÃ¨re fois par Nitesh V. Chawla, SMOTE est une technique basÃ©e sur les plus proches voisins avec une distance euclidienne entre les points de donnÃ©es dans l'espace des caractÃ©ristiques. In [12]: from imblearn.over_sampling import SMOTE sm = SMOTE ( random_state = 42 ) X = df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'duree' ]] y = df [ 'hit' ] X_res , y_res = sm . fit_resample ( X , y ) # Visualisation du changement y_res . value_counts () Out[12]: 1 18280 0 18280 Name: hit, dtype: int64 On remarque que les deux classes ont bien le mÃªme nombre d'observations. L'entrainement du modÃ¨le se fera donc sur des donnÃ©es Ã©quilibrÃ©es. Le critÃ¨re de performance dont on se servira pour l'Ã©valuer est bien accuracy . ModÃ¨le Tout est fin prÃªt pour entraÃ®ner et Ã©valuer notre modÃ¨le. In [13]: import lightgbm as lgb from sklearn.model_selection import train_test_split from sklearn.metrics import auc , accuracy_score , roc_auc_score , roc_curve , confusion_matrix % matplotlib inline import seaborn as sns import matplotlib.pyplot as plt # Fractionnement du dataset en deux sous-jeux: un pour l'entrainement et l'autre pour tester X_train , X_test , y_train , y_test = train_test_split ( X_res , y_res , test_size = 0.30 , random_state = 20 ) # ParamÃ¨tres optimisÃ©s via GridSearch clf = lgb . LGBMClassifier ( boosting_type = 'gbdt' , class_weight = None , colsample_bytree = 1.0 , importance_type = 'split' , learning_rate = 0.2 , max_depth =- 1 , min_child_samples = 20 , min_child_weight = 0.001 , min_split_gain = 0.0 , n_estimators = 100 , n_jobs =- 1 , num_leaves = 31 , objective = None , random_state = None , reg_alpha = 0.0 , reg_lambda = 0.0 , silent = True , subsample = 1.0 , subsample_for_bin = 200000 , subsample_freq = 0 ) clf . fit ( X_train , y_train ) # Ã©valuation de la performance du modÃ¨le y_pred = clf . predict ( X_test ) accuracy = accuracy_score ( y_pred , y_test ) print ( 'Score de prÃ©cision du modÃ¨le : {0:0.4f} ' . format ( accuracy )) Score de prÃ©cision du modÃ¨le : 0.8973 La prÃ©cision du modÃ¨le atteint les 89 %, ce qui est trÃ¨s bien. La visualisation de la matrice de confusion nous permet de comprendre les erreurs commises par notre modÃ¨le-classeur par rapport au sous-jeu de test. In [14]: cm = confusion_matrix ( y_test , y_pred ) mc_matrice = pd . DataFrame ( data = cm , columns = [ 'Classe rÃ©elle:0' , 'Classe rÃ©elle:1' ], index = [ 'Classe prÃ©dite:0' , 'Classe prÃ©dite:1' ]) plt . figure ( figsize = ( 16 , 8 )) ax1 = plt . axes () sns . heatmap ( mc_matrice , ax = ax1 , annot = True , fmt = 'd' , cmap = 'BuPu' ) ax1 . set_title ( 'Matrice de confusion' ) plt . show () La matrice de confusion est une matrice qui mesure la qualitÃ© d'un systÃ¨me de classification. Le diagonal principal reprÃ©sente les observations classÃ©es correctement par le modÃ¨le, et le diagonal secondaire, celles classÃ©es incorrectement. De ce fait, l'erreur la plus frÃ©quente commise par le modÃ¨le est d'avoir classÃ© une chanson en tant que non-hit alors qu'en rÃ©alitÃ© elle Ã©tait hit (837 cas), l'erreur de type II plus prÃ©cisÃ©ment. L'erreur de type I consiste en ce que le modÃ¨le classe une musique comme hit alors qu'elle est non-hit; et l'erreur de type II, l'inverse; c'est-Ã -dire le cas oÃ¹ il classe une musique comme non-hit pourtant elle est hit. Si nous essayons de comprendre la psychologie d'un producteur de musiques, l'erreur de type I est moins acceptable que celle de type II. On ne voudrait pas consentir toutes les dÃ©penses liÃ©es Ã  la production et la promotion d'une musique qu'un modÃ¨le a prÃ©dit 'hit' pour que finalement elle ne le soit pas. La valeur de l'erreur de type I devrait Ãªtre minimale. De maniÃ¨re gÃ©nÃ©rale, le modÃ¨le devrait Ãªtre plus performant. Nous pouvons comprendre Ã  prÃ©sent les variables explicatives ayant le plus de poids dans le processus de classification de notre variable dÃ©pendante en visualisant le graphique d'importance. In [15]: ax = lgb . plot_importance ( clf , height = 0.4 , max_num_features = 10 , importance_type = 'split' , xlim = ( 0 , 500 ), ylim = ( 0 , 10 ), color = 'b' , figsize = ( 16 , 8 )) plt . show () Le graphique d'importance permet la visualisation des variables indÃ©pendantes les plus utiles, dans la prÃ©diction de la variable d'intÃ©rÃªt, par ordre dÃ©croissant. Tempo est la variable explicative la plus importante du modÃ¨le pour la prÃ©diction de la variable hit . Ensuite, les variables explicatives les plus pertinentes sont l' acoustique et la valence , et enfin viennent les autres variables relatives Ã  l'audio. Plus de donnÃ©es, meilleur modÃ¨le AprÃ¨s ajout d'autres variables relatives Ã  l'artiste et Ã  la chanson telles que pop_artiste , tot_followers , marche_disp et pop_chanson dans le modÃ¨le, la prÃ©cision de ce dernier atteint les 98 %, ce qui est excellent comme niveau de performance. Cela signifie que notre modÃ¨le a la capacitÃ© de prÃ©dire si une musique va Ãªtre hit ou non-hit, seulement en se basant sur ces variables de maniÃ¨re gÃ©nÃ©rale, avec plus de 98% de chances que la prÃ©diction soit correcte. In [16]: X = df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'duree' , 'featuring' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'pop_chanson' ]] y = df [ 'hit' ] X_res , y_res = sm . fit_resample ( X , y ) X_train , X_test , y_train , y_test = train_test_split ( X_res , y_res , test_size = 0.30 , random_state = 20 ) clf . fit ( X_train , y_train ) y_pred = clf . predict ( X_test ) accuracy = accuracy_score ( y_pred , y_test ) print ( 'Score de prÃ©cision du modÃ¨le: {0:0.4f} ' . format ( accuracy )) Score de prÃ©cision du modÃ¨le: 0.9806 Matrice de confusion In [17]: cm = confusion_matrix ( y_test , y_pred ) mc_matrice = pd . DataFrame ( data = cm , columns = [ 'Classe rÃ©elle:0' , 'Classe rÃ©elle:1' ], index = [ 'Classe prÃ©dite:0' , 'Classe prÃ©dite:1' ]) plt . figure ( figsize = ( 16 , 8 )) ax2 = plt . axes () sns . heatmap ( mc_matrice , ax = ax2 , annot = True , fmt = 'd' , cmap = 'BuPu' ) ax2 . set_title ( 'Matrice de confusion' ) plt . show () Les erreurs de type I et II sont passÃ©es respectivement de 289 Ã  111 et de 837 Ã  102 cas. Elles sont toutes deux diminuÃ©es et proches. Cela tÃ©moigne du niveau, trÃ¨s proche et faible, de probabilitÃ© pour le modÃ¨le de classer incorrectement une chanson. Visualisons Ã  prÃ©sent le nouveau graphique d'importance. In [18]: ax = lgb . plot_importance ( clf , height = 0.4 , max_num_features = 18 , importance_type = 'split' , xlim = ( 0 , 600 ), ylim = ( 0 , 16 ), color = 'r' , figsize = ( 16 , 8 )) plt . show () Les nouvelles variables augmentent la performance globale du modÃ¨le considÃ©rablement, qui est passÃ©e de 89 Ã  98 %. Elles sont les principales variables indÃ©pendantes dans la dÃ©termination de la classe d'une chanson. Ensuite, viennent les autres variables liÃ©es Ã  l'audio par ordre d'importance. Conclusion Dans cette premiÃ¨re partie de l'article, nous avons construit un modÃ¨le pouvant classer une chanson en hit ou non-hit suivant des variables lui Ã©tant propres. Pour y parvenir, nous avons utilisÃ© Billboard et Spotify pour construire notre jeu de donnÃ©es. Une brÃ¨ve visualisation des donnÃ©es a Ã©tÃ© effectuÃ©e avant d'entraÃ®ner le modÃ¨le. Nous avons mis en application les techniques de Â« feature engineering Â» afin de normaliser les donnÃ©es. La technique SMOTE nous a Ã©tÃ© utile afin d'assurer la gestion de nos donnÃ©es qui, au regard des modalitÃ©s de notre variable dÃ©pendante Â« hit Â», Ã©taient dÃ©sÃ©quilibrÃ©es, . AprÃ¨s avoir entraÃ®nÃ© et Ã©valuÃ© le modÃ¨le uniquement avec les donnÃ©es liÃ©es aux caractÃ©ristiques d'audio des musiques, une prÃ©cision de 86 % a Ã©tÃ© obtenue; et, aprÃ¨s ajout d'autres variables liÃ©es au profil de l'artiste dans le modÃ¨le, la prÃ©cision a atteint les 98 %. De notre analyse il faut retenir ceci: essentiellement, une musique est Â« hit Â» si elle est populaire sur Spotify, est interpretÃ©e par un artiste lui-mÃªme populaire sur Spotify et possÃ¨de un nombre important de followers, et enfin, si elle est disponible dans le plus grand nombre de pays Ã  travers le monde. Cette conclusion semble logique, mais elle est aussi vÃ©rifiÃ©e empiriquement par notre modÃ¨le. GÃ©nÃ©ralement, une musique possÃ¨de une autre caractÃ©ristique importante que nous n'avons pas encore prise en compte: les paroles. Pouvons-nous augmenter davantage la performance du modÃ¨le en nous servant des lyriques? C'est ce que nous allons explorer dans la deuxiÃ¨me partie de l'article. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Machine Learning","url":"https://jbobym.github.io/PrÃ©diction_des_prochaines_musiques_hits_(partie_1)","loc":"https://jbobym.github.io/PrÃ©diction_des_prochaines_musiques_hits_(partie_1)"}]};