var tipuesearch = {"pages":[{"title":"Prédiction des prochaines musiques hits (partie 1)","text":"Introduction Des milliers de chansons voient le jour tous les ans dans le monde. Certaines connaissent de vrais succès dans l'industrie musicale ; d'autres le sont moins. Il est un fait que réussir dans cette industrie demeure une tâche difficile. Investir dans la production d'une chanson requiert des activités diversifiées et peuvent consommer beaucoup de ressources. Il n'y a aucun outil jusque-là automatique dont les artistes et producteurs pourraient s'en servir pour évaluer si leur chanson qu'ils sont sur le point de publier va se révéler 'hit'. Dans cet article, on cherchera à comprendre ce qui caractérise une chanson populaire, et plus précisement si l'on pourrait prédire la popularité d'une chanson seulement en nous basant sur ses caractéristiques d'audio et celles de l'artiste. Nous allons construire un modèle-classeur de machine learning pouvant classer une chanson en hit ou non-hit. Bien que des facteurs sociaux comme le contexte dans lequel la chanson a été diffusée, la démographie de ses auditeurs et l'effectivité de sa campagne de marketing peuvent tout aussi bien jouer un rôle important dans sa viralité, nous emettons l'hypothèse que les caractéristiques inhérentes à une chanson, tels que l'artiste qui l'interprète, sa duréee, ses caractéristiques d'audio peuvent être correlés et également révélateur de sa viralité. Construction du jeu de données Dans cet article de deux parties, nous allons essayer de construire un modèle de machine learning comme un classeur de chansons en hits et non-hits. Pour réussir un tel travail, plus avons de données, mieux c'est. Etant donné qu'on n'a pas pu trouver un dataset venant d'une seule et unique source avec toutes les variables, il nous a fallu recourir au data enrichment à mesure que cela ait été nécessaire. Nous avons eu besoin de trois sources pour construire notre jeu de données. Et l'opération de recueillement s'est déroulée de la manière suivante : Billboard : On s'est servi de la page Wikipédia de Bilboard Year-End Hot 100 pour recueillir les musiques les plus populaires (hits) pour les années allant de 2010 à 2019. On a utilisé le web scrapping pour accomplir cette tâche. Spotify : Ensuite on a utilisé la librairie Spotipy pour récupérer les caractéristiques relatives à l'audio tels que la dansabilité, la vivacité, l'instrumentalité, etc. et à l'artiste comme la popularité, le nombre de followers etc. à la fois des chansons hits provenant du Billboard Year-End Hot 100 et d'autres chansons non-hits sur la période. LyricsOnDemand : Enfin LyricsOnDemand sera utilisé principalement pour récupérer les paroles des chansons. On considère qu'une musique de notre dataset est hit si elle a fait partie du classement du Billboard Year-End Hot 100 au moins une fois pendant l'une des années sur la période considérée. En d'autres termes, notre modèle aura pour mission de prédire si une chanson fera partie de la liste des 100 musiques les plus populaires de Bilboard ou non. Nous avons executé pas mal de lignes de codes afin de construire notre jeu de données. Tous les codes du projet sont accessibles depuis ma page github . Outils: La librairie Spotipy pour accéder aux données de la plateforme musicale de Spotify Seaborn et matplotlib pour la visualisation des données Pandas et numpy pour l'analyse des données scikit-learn pour la construction du modèle de machine learning Les variables Spotify est l'une des plus grandes plateformes de streaming dans le monde. A l'instar de Twitter ou Facebook, elle fournit une API (Application Programming Interface) pour que les developpeurs puissent interagir avec son immense base de données musicale. Via cet API, j'ai pu recolleter des données pour plus de 22 000 chansons; chaque chanson étant caracterisée par à peu près une vingtaine de variables. Les variables retournées par l'API sont aussi riches en information que variées. Toutefois, j'ai selectionné uniquement celles qui sont jugées pertinentes pour le travail. Ensuite, elles ont été transformées via les techniques de feature engineering afin de préparer le jeu de données au mieux pour l'entraînement du modèle. Vous trouverez ci-dessous le nom et la déscription de chaque variable utilisée. Les variables relatives à l'artiste nom_artiste : Nom de l'artiste principal de la chanson. Popularité : La popularité de l'artiste sur Spotify. La valeur sera comprise entre 0 et 100, 100 étant le plus populaire. Nous pensons que plus un artiste est populaire, plus une chanson sur laquelle il pose sa voix est susceptible d'être virale. Followers : Nombre total de followers sur Spotify. Les variables relatives à la chanson Date de sortie : Date à laquelle la chanson a été diffusée pour la première fois. Marché disponible : Nombre de pays dans lequel la chanson peut être jouée. Durée : La durée de la chanson en millisecondes. Acoustique : Une mesure de confiance de 0.0 à 1.0 indiquant si la chanson est acoustique. 1.0 représente une confiance élevée que la chanson est acoustique. Dansabilité : La dansabilité décrit à quel point une chanson est adaptée à la danse sur la base d'une combinaison d'éléments musicaux, notamment le tempo, la stabilité du rythme, la force du rythme et la régularité globale. Une valeur de 0.0 est la moins dansante et 1.0 est la plus dansante. Energie : L'énergie est une mesure de 0.0 à 1.0 et représente une mesure perceptuelle de l'intensité et de l'activité. En règle générale, les chansons énergiques sont rapides, sonores et bruyantes. Instrumentalité : Prédit si une chanson ne contient pas de voix. Les sons «Ooh» et «aah» sont traités comme instrumentaux dans ce contexte. Les morceaux de rap ou de mots parlés sont clairement «vocaux». Plus la valeur instrumentale est proche de 1.0, plus la piste ne contient aucun contenu vocal. Les valeurs supérieures à 0.5 sont censées représenter des chansons instrumentales, mais la confiance est plus élevée lorsque la valeur approche de 1.0. Vivacité : Détecte la présence d'un public dans l'enregistrement. Des valeurs de vivacité plus élevées représentent une probabilité accrue que la chanson ait été jouée en direct. Une valeur supérieure à 0.8 offre une forte probabilité que la chanson soit en direct. Intensité : L'intensité global d'une chanson en décibels (dB). Les valeurs d'intensité sont moyennées sur toute la chanson et sont utiles pour comparer l'intensité relative des chansons. L'intensité sonore est la qualité d'un son qui est le principal corrélat psychologique de la force physique (amplitude). Les valeurs varient entre -60 et 0 db. Eloquence : L'éloqunece détecte la présence de mots prononcés dans une chanson. Plus l'enregistrement est exclusivement vocal (par exemple, talk-show, livre audio, poésie), plus la valeur d'attribut est proche de 1.0. Les valeurs supérieures à 0.66 décrivent des chansons qui sont probablement entièrement constituées de mots prononcés. Les valeurs comprises entre 0.33 et 0.66 décrivent des pistes qui peuvent contenir à la fois de la musique et de la parole, soit en sections, soit en couches, y compris des cas comme la musique rap. Les valeurs inférieures à 0.33 représentent très probablement de la musique et d'autres pistes non vocales. Valence : Une mesure de 0.0 à 1.0 décrivant la positivité musicale véhiculée par une chanson. Les chansons avec une valence élevée semblent plus positives (par exemple, joyeuses, gaies, euphoriques), tandis que les chansons avec une valence basse semblent plus négatives (par exemple tristes, déprimées, en colère). Tempo : Le tempo global estimé d'une chanson en battements par minute (BPM). Dans la terminologie musicale, le tempo est la vitesse ou le rythme d'une pièce donnée et découle directement de la durée moyenne des temps. hit : Variable dichotomique mesurant si une chanson est hit ou non. Elle prend la valeur de 1 si la chanson est hit, 0 sinon. C'est notre variable dépendante, c'est-à-dire celle que l'on cherchera à prédire pour une chanson donnée. featuring : Variable dépendante dichotomique mesurant s'il y a un ou plusieurs artistes invités sur une chanson. mois : Mois de sortie de la chanson. jour_sem : Jour de la semaine durant lequel la chanson a ete diffusee. jour : Jour de sortie de la chanson. Certaines de ces variables sont utilisées uniquement pour l'analyse, d'autres participent à toutes les étapes du pipeline. A présent, jettons un coup d'oeil sur la dimension de notre jeu de données. In [1]: # Cellule à enlever import pandas as pd import numpy as np df1 = pd . read_csv ( r 'C:\\Users\\Kathee\\Documents\\Blog content\\bilboard_data.csv' ) df1 . drop ([ 'key' ], axis = 1 , inplace = True ) df2 = pd . read_csv ( r 'C:\\Users\\Kathee\\Documents\\Blog content\\spotify_data_20000.csv' ) df1 [ 'pop' ] = 1 df2 [ 'pop' ] = 0 df = pd . concat ([ df1 , df2 ]) def feat_ ( row ): if 'feat.' in row [ 'track_name' ]: val = 1 else : val = 0 return val df [ 'featuring' ] = df . apply ( feat_ , axis = 1 ) df [ 'search' ] = df [ 'artist_name' ] + \" \" + df [ \"track_name\" ] df = df . drop_duplicates ( subset = [ 'search' ], keep = 'first' ) df . shape df = df . rename ( columns = { 'artist_name' : 'nom_artiste' , 'pop_artist' : 'pop_artiste' , 'track_name' : 'nom_chanson' , 'avail_mark' : 'marche_disp' , 'rel_date' : 'date_sortie' , 'pop_track' : 'pop_chanson' , 'acousticness' : 'acoustique' , 'danceability' : 'dansabilite' , 'duration_ms' : 'duree' , 'energy' : 'energie' , 'instrumentalness' : 'instrumentalite' , 'liveness' : 'vivacite' , 'loudness' : 'intensite' , 'speechiness' : 'eloquence' , 'tempo' : 'tempo' , 'valence' : 'valence' , 'pop' : 'hit' , 'featuring' : 'featuring' }) df [ 'date_sortie' ] = pd . to_datetime ( df [ 'date_sortie' ]) df [ 'mois_sortie' ] = df [ 'date_sortie' ] . apply ( lambda m : m . month ) df [ 'jour_sortie' ] = df [ 'date_sortie' ] . apply ( lambda d : d . day ) df [ 'jour_sem_sortie' ] = df [ 'date_sortie' ] . apply ( lambda w : w . weekday ()) In [2]: df . shape Out[2]: (19182, 24) Après avoir choisi les variables disponibles jugées pertinentes pour le modèle, supprimé les observations contenant des valeurs manquantes et les duplications, notre jeu est réduit à 19 120 observations contenant 24 variables chacune. Les 5 premières observations de notre jeu sont les suivantes. In [3]: df . head ( n = 5 ) Out[3]: nom_artiste pop_artiste tot_followers nom_chanson marche_disp date_sortie pop_chanson acoustique dansabilite duree ... eloquence tempo time_signature valence hit featuring search mois_sortie jour_sortie jour_sem_sortie 0 Kesha 81 5470072 TiK ToK 79 2010-01-01 79 0.09910 0.755 199693 ... 0.1420 120.028 4 0.714 1 0 Kesha TiK ToK 1 1 4 1 Lady Antebellum 74 2933375 Need You Now 78 2010-01-01 69 0.09270 0.587 277573 ... 0.0303 107.943 4 0.231 1 0 Lady Antebellum Need You Now 1 1 4 2 Train 77 3249275 Hey, Soul Sister 79 2010-12-01 82 0.18500 0.673 216773 ... 0.0431 97.012 4 0.795 1 0 Train Hey, Soul Sister 12 1 2 3 Katy Perry 87 15347727 California Gurls 79 2012-03-12 72 0.00446 0.791 234653 ... 0.0569 125.014 4 0.425 1 0 Katy Perry California Gurls 3 12 0 4 Usher 82 7654666 OMG (feat. will.i.am) 79 2010-03-30 71 0.19800 0.781 269493 ... 0.0332 129.998 4 0.326 1 1 Usher OMG (feat. will.i.am) 3 30 1 5 rows × 24 columns Visualisation In [4]: #%%capture % matplotlib inline from matplotlib import pyplot as plt fig = plt . figure ( figsize = ( 16 , 8 )) ax = fig . add_axes ([ 0 , 0 , 1 , 1 ]) pop = [ 'non-hit' , 'hit' ] pop_count = list ( df [ 'hit' ] . value_counts ()) ax . bar ( pop , pop_count , color = '#293484' ) for i , v in enumerate ( pop_count ): ax . text ( i -. 05 , v + 100 , pop_count [ i ], fontsize = 12 , color = 'black' ) plt . title ( 'Distribution des nombres de chansons \\n suivant les modalités de la variable hit.' ) plt . ylabel ( 'nombre_de_chansons' ) plt . xlabel ( 'classe' ) plt . show () La distribution de la variable hit est telle que seulement 902 chansons du jeu de données sont hits, alors que 18280 ne le sont pas. Il y a lieu de contaster un déséquilibre flagrant au sein de notre variable d'interêt. On règlera ce souci plus tard avant de passer à la phase d'entraînement de notre modèle. In [5]: #%%capture fig ,( ax1 , ax2 , ax3 ) = plt . subplots ( 1 , 3 , figsize = ( 18 , 8 )) fig . suptitle ( 'Date de sortie des musiques hits' ) ax1 . set_title ( 'Mois' ) ax1 . hist ( df [ df [ 'hit' ] == 1 ][ 'mois_sortie' ], bins = 30 , color = 'blue' ) ax2 . set_title ( 'Jour de la semaine' ) ax2 . hist ( df [ df [ 'hit' ] == 1 ][ 'jour_sem_sortie' ], bins = 14 , color = 'red' ) ax3 . set_title ( 'Jour' ) ax3 . hist ( df [ df [ 'hit' ] == 1 ][ 'jour_sortie' ], bins = 62 , color = 'blue' ) plt . show () A la lumière du graphique ci-dessus, janvier est le mois durant lequel plus de musiques hits sont sorties; juillet étant le mois le moins solicité. On remarque aussi que la majorité des hits de la période sont sortis le 4ème jour de la semaine; soit jeudi. Enfin le premier jour du mois est largement plus utilisé pour publier une chanson. Fort de ce constat, on peut déduire que publier une chanson le premier janvier, c'est probablement un pas vers l'optimisation des chances de sa viralité. On doit tout de même être prudent, corrélation n'est pas causalité. Il faudrait pousser notre analyse plus en profondeur afin d'être plus précis dans cette conclusion. Quels sont les artistes les plus populaires sur la période considérée? In [6]: #%%capture plt . figure ( figsize = ( 16 , 8 )) artistes = df [ df [ 'hit' ] == 1 ][ 'nom_artiste' ] . value_counts ()[: 20 ] artistes . plot ( kind = \"bar\" , color = 'blue' ) plt . title ( \"Les artistes avec le plus de musiques hits\" ) plt . show () Sans surprise aucune, les artistes comme Drake, Rihanna et Taylor Swift ont enregistré plus de musiques hits que quiconque autre artiste sur la période. Ceci étant dit, il est plausible de croire qu'une chanson a plus de chances d'être virale si elle contient la voix de l'un de ces artistes. In [7]: #%%capture plt . figure ( figsize = ( 16 , 8 )) plt . hist ( df [ df [ 'hit' ] == 1 ][ 'pop_artiste' ], bins = 100 , density = True , alpha = 0.5 , label = \"hit\" , color = 'blue' ) plt . hist ( df [ df [ 'hit' ] == 0 ][ 'pop_artiste' ], bins = 100 , density = True , alpha = 0.5 , label = \"non-hit\" , color = 'red' ) plt . title ( \"Popularité des artistes\" ) plt . legend () plt . show () Les deux distributions sont assymétriques à droite. Cependant, l'assymétrie de la distribution des musiques hits est plus prononcée. 75 % des musiques non-hits ont des artistes dont la popularité est inférieure à 82, alors que seulement la popularité des artistes de 50 % des musiques hits est inférieure à ce nombre. pop_artiste pourrait être une variable explicative importante dans la prédiction de notre variable d'intérêt. Quid de la répartitition des variables d'audio au sein des deux catégories? In [36]: #%%capture import numpy as np from matplotlib import pyplot as plt features_hit = df . loc [ df [ 'hit' ] == 1 ,[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'eloquence' , 'valence' ]] features_non_hit = df . loc [ df [ 'hit' ] == 0 ,[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'eloquence' , 'valence' ]] N = len ( features_hit . mean ()) #Liste des nombre de variables ind = np . arange ( N ) width = 0.25 #diagrame en batons avec la liste des musiques hits plt . barh ( ind , features_hit . mean () , width , label = 'hits' , color = 'blue' ) #diagrame en batons avec la liste des musiques non hits plt . barh ( ind + width , features_non_hit . mean (), width , label = 'non-hits' , color = 'red' ) #X- label plt . xlabel ( 'Moyenne' , fontsize = 12 ) # Title plt . title ( \"Distribution des valeurs moyennes \\n des caractéristiques d'audio des chansons.\" ) #Vertical ticks plt . yticks ( ind + width / 2 , ( list ( features_non_hit )[:]), fontsize = 12 ) #legend plt . legend ( loc = 'best' ) # Figure size plt . rcParams [ 'figure.figsize' ] = ( 16 , 8 ) # Set style plt . style . use ( \"ggplot\" ) plt . show () Les variables prédominantes au sein des deux catégories sont les mêmes : energie , dansabilité et valence . La seule difference est que les valeurs moyennées de ces variables sont plus élevées pour la catégorie des chansons hits. Ceci atteste que les musiques hits sont plus rapides et sonores. Elles sont plus adaptées à la danse et sont plus enclines à inspirer la joie, la gaité, l'euphorie. L'approche de machine learning Jusque-là, nous avons pu découvrir quelques interéssants insights sur les données. Afin d'écourter cet article, passons directement en la partie concernant l'algorithme de machine learning que nous allons utiliser. Nous allons construire un modèle afin de prédire la classe, hit ou non-hit, qu'une musique est la plus susceptible d'appartenir en nous basant sur un ensemble de variables explicatives, comme expliqué au début. Il est important de garder en tête que nous voulons un modèle qui soit le plus performant possible. Nous allons utiliser l'algorithme de classification de LightGBM . Pourquoi? J'ai découvert ce framework récemment alors que je participais à une compétition sur Kaggle. Ses résultats sont robustes. Il est largement utilisé dans de nombreuses solutions gagnantes de concours de machine learning. En guise d'expliquer comment l'algorithme fonctionne, on se contentera de mentionner que c'est une approche de machine learning supervisé que l'on va utiliser et que LightGBM est un framework de gradient boosting qui utilise des algorithmes d'apprentissage basés sur des arbres. Il est conçu pour être distribué et efficient avec les avantages suivants: Vitesse d'entraînement plus rapide et efficacité plus élevée. Utilisation réduite de la mémoire. Meilleure précision. Prise en charge de l'apprentissage parallèle et GPU. Capable de gérer des données à grande échelle. Suppression de variables La première étape dans la préparation de notre jeu de données pour l'entrainement du modèle est de nous assurer que toutes les colonnes sont de valeurs numériques. C'est en ce sens que nous avons supprimé les variables comme nom_chanson, search, nom_artiste, date_sortie, jour_sortie, jour_sem_sortie et mois_sortie. In [9]: df . drop ([ 'nom_chanson' , 'search' , 'nom_artiste' , 'date_sortie' , 'jour_sem_sortie' , 'jour_sortie' , 'mois_sortie' , 'time_signature' ], axis = 1 , inplace = True ) Feature engineering A ce stade on recourt à plusieurs techniques afin d'optimiser notre jeu de données. En realité, on en a déjà appliqué quelques-unes au début lorsqu'il était question de gérer les valeurs manquantes, les dupplications, l'extraction des dates, One-Hot-Encoding, etc. A présent nous allons appliquer la technique dite scaling sur quelques variables du jeu. Cette technique a la vertu de mettre toutes les variables numériques sur une même base comparable. Bien, à quoi ressemble notre jeu maintenant? In [10]: from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler () df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'duree' , 'pop_chanson' ]] = scaler . fit_transform ( df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'duree' , 'pop_chanson' ]]) In [11]: df . head ( n = 2 ) Out[11]: pop_artiste tot_followers marche_disp pop_chanson acoustique dansabilite duree energie instrumentalite vivacite intensite eloquence tempo valence hit featuring 0 0.81 0.084919 1.000000 0.822917 0.099498 0.771195 0.031525 0.836997 0.000000 0.291919 0.933029 0.149474 0.545336 0.721212 1 0 1 0.74 0.045538 0.987179 0.718750 0.093072 0.599591 0.046020 0.621992 0.000636 0.202020 0.882599 0.031895 0.490429 0.233333 1 0 Vueillez remarquer que toutes les variables quantitatives indépendantes sont comprises dans l'intervalle [0,1]. Dans la réalité, cela ne fait aucun sens qu'une variable tel que tot_followers par exemple contienne des valeurs entre 0 et 1. Mais du point de vue de l'algorithme, cela a tout son sens car c'est par ce procédé que les variables deviennent comparables. Les algorithmes de machine learning fonctionnent mieux lorsque les variables indépendantes sont relativement à une échelle similaire et proches de la distribution normale. Suréchantillonage des données Rappelons-nous qu'au regard de la variable dépendante, notre jeu de données est très déséquilibré. La catégorie hit est sous-représentée par rapport à la classe non-hit. Pour y remédier, nous allons recourir à la téchinque dite SMOTE. SMOTE (Synthetic Minority Over-Sampling TEchnique) est une technique utilisée pour traiter des ensembles de données déséquilibrées. Introduite pour la première fois par Nitesh V. Chawla, SMOTE est une technique basée sur les plus proches voisins avec une distance euclidienne entre les points de données dans l'espace des caractéristiques. In [12]: from imblearn.over_sampling import SMOTE sm = SMOTE ( random_state = 42 ) X = df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'duree' ]] y = df [ 'hit' ] X_res , y_res = sm . fit_resample ( X , y ) # Visualisation du changement y_res . value_counts () Out[12]: 1 18280 0 18280 Name: hit, dtype: int64 On remarque que les deux classes ont bien le même nombre d'observations. L'entrainement du modèle se fera donc sur des données équilibrées. Le critère de performance dont on se servira pour l'évaluer est bien accuracy . Modèle Tout est fin prêt pour entraîner et évaluer notre fameux modèle. In [13]: import lightgbm as lgb from sklearn.model_selection import train_test_split from sklearn.metrics import auc , accuracy_score , roc_auc_score , roc_curve , confusion_matrix % matplotlib inline import seaborn as sns import matplotlib.pyplot as plt # Fractionnement du dataset en deux sous-jeux: un pour l'entrainement et l'autre pour tester X_train , X_test , y_train , y_test = train_test_split ( X_res , y_res , test_size = 0.30 , random_state = 20 ) # Paramètres optimisés via GridSearch clf = lgb . LGBMClassifier ( boosting_type = 'gbdt' , class_weight = None , colsample_bytree = 1.0 , importance_type = 'split' , learning_rate = 0.175 , max_depth =- 1 , min_child_samples = 20 , min_child_weight = 0.001 , min_split_gain = 0.0 , n_estimators = 100 , n_jobs =- 1 , num_leaves = 31 , objective = None , random_state = None , reg_alpha = 0.0 , reg_lambda = 0.0 , silent = True , subsample = 1.0 , subsample_for_bin = 200000 , subsample_freq = 0 ) clf . fit ( X_train , y_train ) # évaluation de la performance du modèle y_pred = clf . predict ( X_test ) accuracy = accuracy_score ( y_pred , y_test ) print ( 'Score de précision du modèle : {0:0.4f} ' . format ( accuracy )) Score de précision du modèle : 0.8919 La précision du modèle atteint les 89 %, ce qui est très bien. La visualisation de la matrice de confusion nous permet de comprendre les erreurs commises par notre modèle-classeur par rapport au sous-jeu de test. In [14]: cm = confusion_matrix ( y_test , y_pred ) mc_matrice = pd . DataFrame ( data = cm , columns = [ 'Classe réelle:0' , 'Classe réelle:1' ], index = [ 'Classe prédite:0' , 'Classe prédite:1' ]) plt . figure ( figsize = ( 16 , 8 )) ax1 = plt . axes () sns . heatmap ( mc_matrice , ax = ax1 , annot = True , fmt = 'd' , cmap = 'BuPu' ) ax1 . set_title ( 'Matrice de confusion' ) plt . show () La matrice de confusion est une matrice qui mesure la qualité d'un système de classification. Le diagonal principal représente les observations clasées correctement par le modèle, et le diagonal secondaire, celles classées incorrectement. De ce fait, l'erreur la plus fréquente commise par le modèle est d'avoir classé une chanson en tant que non-hit alors qu'en realité elle était hit (1039 cas), l'erreur de type II plus précisément. Si on essaie de comprendre la psychologie d'un producteur de musiques, l'erreur du type I est moins acceptable que celle de type II. On ne voudrait pas consentir toutes les dépenses liées à une musique qu'un modèle a prédit 'hit' pour que finalement elle ne l'est pas. La valeur de l'erreur du type I devrait être minimale. De manière générale, le modèle devrait être plus perfomant. Nous pouvons comprendre à présent les variables explicatives ayant le plus de poids dans le processus de classification de notre variable dépendante en visualisant le graphique d'importance. In [15]: #plt.figure(figsize=(16,8)) ax = lgb . plot_importance ( clf , height = 0.4 , max_num_features = 10 , importance_type = 'split' , xlim = ( 0 , 500 ), ylim = ( 0 , 10 ), color = 'b' , figsize = ( 16 , 8 )) plt . show () Le graphique d'importance permet la visualisation des variables indépendantes les plus utiles, dans la prédiction de la variable d'intérêt, par ordre décroissant. Tempo est la variable explicative la plus importante du modèle pour la prédiction de la variable hit . Ensuite, les variables explicatives les plus pertinentes sont l' acoustique et la valence , et enfin viennent les autres variables relatives à l'audio. Plus de données, meilleur modèle Après ajout d'autres variables relatives à l'artiste et à la chanson telles que pop_artiste , tot_followers , marche_disp et pop_chanson dans le modèle, la précision de ce dernier atteint les 97 %, ce qui est excellent comme niveau de performance. Notre modèle a la capacité de prédire si une musique va être hit ou non-hit, seulement en se basant sur ces variables de manière générale, avec plus de 98% de chances que la prédiction soit correcte. In [16]: X = df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'duree' , 'featuring' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'pop_chanson' ]] y = df [ 'hit' ] X_res , y_res = sm . fit_resample ( X , y ) X_train , X_test , y_train , y_test = train_test_split ( X_res , y_res , test_size = 0.30 , random_state = 20 ) clf . fit ( X_train , y_train ) y_pred = clf . predict ( X_test ) accuracy = accuracy_score ( y_pred , y_test ) print ( 'Score de précision du modèle: {0:0.4f} ' . format ( accuracy )) Score de précision du modèle: 0.9805 Matrice de confusion In [17]: cm = confusion_matrix ( y_test , y_pred ) mc_matrice = pd . DataFrame ( data = cm , columns = [ 'Classe réelle:0' , 'Classe réelle:1' ], index = [ 'Classe prédite:0' , 'Classe prédite:1' ]) plt . figure ( figsize = ( 16 , 8 )) ax2 = plt . axes () sns . heatmap ( mc_matrice , ax = ax2 , annot = True , fmt = 'd' , cmap = 'BuPu' ) ax2 . set_title ( 'Matrice de confusion' ) plt . show () Les erreurs de type I et II sont passées respectivement de 433 à 138 cas et de 1039 à 137 cas. Elles sont diminuées et quasiment au même niveau. Cela témoigne de la probabilité égale pour le modèle de classer incorrectement une chanson. Visualisons à présent le nouveau graphique d'importance. In [18]: ax = lgb . plot_importance ( clf , height = 0.4 , max_num_features = 18 , importance_type = 'split' , xlim = ( 0 , 800 ), ylim = ( 0 , 16 ), color = 'r' , figsize = ( 16 , 8 )) plt . show () Les nouvelles variables augmentent la performance globale du modèle, qui est passée de 89 à 98 %. Elles sont les principales variables indépendantes dans la détermination de la classe d'une chanson. Ensuite, viennent les autres variables liées à l'audio par ordre d'importance. Conclusion Dans cette première partie de l'article, on a construit un modèle pouvant classer une chanson en hit ou non-hit suivant des variables lui étant propres. De notre analyse il faut retenir ceci: esentiellement, une chanson est hit si elle populaire sur Spotify, est interpretée par un artiste lui-même populaire sur Spotify et possède un nombre important de followers, et enfin si elle est disponible dans le plus grand nombre de pays à travers le monde. Cette conclusion me semble logique, mais elle est aussi vérifée empiriquement par notre modèle. Généralement, une musique possède une autre caractéristique importante qu'on n'a pas encore prise en compte: les paroles. Pouvons-nous augmenter davantage la performance du modèle en nous des lyriques? C'est ce que nous allons explorer dans la deuxième partie de l'article. Il m'est toujours un plaisir de recevoir des feedback à propos de mon travail. Si vous avez des suggestions ou des commentaires, n'hésitez pas à me contacter via twitter ou me les adresser sous la forme d'un commentaire Disqus.","tags":"Machine Learning","url":"https://jbobym.github.io/Prédiction_des_prochaines_musiques_hits_(partie_1)","loc":"https://jbobym.github.io/Prédiction_des_prochaines_musiques_hits_(partie_1)"}]};