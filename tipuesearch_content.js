var tipuesearch = {"pages":[{"title":"Prédiction des prochaines musiques hits (partie 1)","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Des milliers de chansons voient le jour tous les ans dans le monde. Certaines connaissent de vrais succès dans l'industrie musicale ; d'autres moins. Il est un fait que réussir dans cette industrie demeure une tâche difficile. Investir dans la production d'une chanson requiert des activités diversifiées et peuvent consommer beaucoup de ressources. Jusque-là, il n'y a aucun outil automatique qui permettrait aux artistes et aux producteurs d'évaluer que la chanson qu'ils vont publier sera un « hit musical ». Dans cet article, nous chercherons à comprendre ce qui caractérise une chanson populaire, et plus précisément comment il serait possible de prédire la popularité d'une chanson en nous basant uniquement sur ces caractéristiques d'audio et sur le profil de l'artiste. Pour répondre à cette question, nous allons construire un modèle-classeur de machine learning pouvant classer une chanson en hit ou non-hit. Bien que des facteurs sociaux comme le contexte dans lequel la chanson a été diffusée, la démographie de ses auditeurs et l'effectivité de sa campagne de marketing peuvent tout aussi bien jouer un rôle important dans sa viralité, nous émettons l'hypothèse que les caractéristiques inhérentes à une chanson, tels que l'artiste qui l'interprète, sa durée, ses caractéristiques d'audio peuvent être corrélés et également révélateur de sa viralité. Construction du jeu de données Plus nous avons de données pertinentes, mieux sera la capacité prédictive de notre modèle. Nous n'avons pas pu disposer d'un dataset venant d'une seule et unique source qui comporterait toutes les variables. Alors, il nous a fallu recourir aux techniques de « data enrichment ». Notre jeu de données a été construit à partir de trois (3) sources de données en suivant la méthode suivante : Nous avons utilisé la page Wikipédia de Billboard Year-End Hot 100 pour recueillir les musiques les plus populaires (hits) datant de 2010 à 2019. On a utilisé le web scrapping pour accomplir cette tâche. Ensuite, nous avons utilisé le package Spotipy pour récupérer les caractéristiques relatives, d'une part, à l'audio telles que la dansabilité, la vivacité, l'instrumentalité, etc; et d'autre part, à l'artiste comme la popularité, le nombre de followers etc. pour des chansons hits provenant du Billboard Year-End Hot 100 et d'autres chansons non-hits de la même période. Et enfin, Genius sera utilisé principalement pour la récupération des paroles des chansons que nous avons recueillies. Une musique de notre dataset est considérée comme un « hit » si elle a fait partie du classement du Billboard Year-End Hot 100 au moins une fois pendant l'une des années sur la période considérée. En d'autres termes, notre modèle aura pour mission de prédire si une chanson fera partie de la liste des 100 musiques les plus populaires de Billboard ou non. Notre jeu de données est construit à partir d'un programme Python, utilisant des packages parmi les plus utilisés en data science. Tous les codes du projet sont accessibles ici . Outils utilisés: Le package spotipy pour accéder aux données de la plateforme musicale de Spotify seaborn et matplotlib pour la visualisation des données pandas et numpy pour l'analyse des données La librairie scikit-learn pour la construction du modèle de machine learning Les variables Spotify est l'une des plus grandes plateformes de streaming dans le monde. A l'instar de Twitter ou Facebook, elle fournit une API (Application Programming Interface) pour que les developpeurs puissent interagir avec son immense base de données musicale. Via des endpoints de cet API, j'ai pu récolter des données pour plus de 22 000 chansons; chaque chanson étant caracterisée par environ une vingtaine de variables. Les variables retournées par l'API sont aussi riches en information que variées. Toutefois, j'ai selectionné uniquement celles qui sont jugées pertinentes pour le travail. Ensuite, elles ont été transformées via les techniques de feature engineering afin de préparer le jeu de données au mieux pour l'entraînement du modèle. Vous trouverez ci-dessous le nom et la description de chaque variable utilisée. Les variables relatives à l'artiste nom_artiste : Nom de l'artiste principal de la chanson. Popularité : La popularité de l'artiste sur Spotify. La valeur sera comprise entre 0 et 100, 100 étant le plus populaire. Nous pensons que plus un artiste est populaire, plus une chanson sur laquelle il pose sa voix est susceptible d'être virale. Followers : Nombre total de followers sur Spotify. Les variables relatives à la chanson Date de sortie : Date à laquelle la chanson a été diffusée pour la première fois. Marché disponible : Nombre de pays dans lequel la chanson peut être jouée. Durée : La durée de la chanson en millisecondes. Acoustique : Une mesure de confiance de 0.0 à 1.0 indiquant si la chanson est acoustique. 1.0 représente une confiance élevée que la chanson est acoustique. Dansabilité : La dansabilité décrit à quel point une chanson est adaptée à la danse sur la base d'une combinaison d'éléments musicaux, notamment le tempo, la stabilité du rythme, la force du rythme et la régularité globale. Une valeur de 0.0 est la moins dansante et 1.0 est la plus dansante. Energie : L'énergie est une mesure de 0.0 à 1.0 et représente une mesure perceptuelle de l'intensité et de l'activité. En règle générale, les chansons énergiques sont rapides, sonores et bruyantes. Instrumentalité : Celle-ci prédit si une chanson ne contient pas de voix. Les sons «Ooh» et «aah» sont traités comme instrumentaux dans ce contexte. Les morceaux de rap ou de mots parlés sont clairement «vocaux». Plus la valeur instrumentale est proche de 1.0, plus la piste ne contient aucun contenu vocal. Les valeurs supérieures à 0.5 sont censées représenter des chansons instrumentales, mais la confiance est plus élevée lorsque la valeur approche de 1.0. Vivacité : Détecte la présence d'un public dans l'enregistrement. Des valeurs de vivacité plus élevées représentent une probabilité accrue que la chanson ait été jouée en direct. Une valeur supérieure à 0.8 offre une forte probabilité que la chanson soit en direct. Intensité : L'intensité globale d'une chanson en décibels (dB). Les valeurs d'intensité sont moyennées sur toute la chanson et sont utiles pour comparer l'intensité relative des chansons. L'intensité sonore est la qualité d'un son qui est le principal corrélat psychologique de la force physique (amplitude). Les valeurs varient entre -60 et 0 db. Eloquence : L'éloqunece détecte la présence de mots prononcés dans une chanson. Plus l'enregistrement est exclusivement vocal (par exemple, talk-show, livre audio, poésie), plus la valeur d'attribut est proche de 1.0. Les valeurs supérieures à 0.66 décrivent des chansons qui sont probablement entièrement constituées de mots prononcés. Les valeurs comprises entre 0.33 et 0.66 décrivent des pistes qui peuvent contenir à la fois de la musique et de la parole, soit en sections, soit en couches, y compris des cas comme la musique rap. Les valeurs inférieures à 0.33 représentent très probablement de la musique et d'autres pistes non vocales. Valence : Une mesure de 0.0 à 1.0 décrivant la positivité musicale véhiculée par une chanson. Les chansons avec une valence élevée semblent plus positives (par exemple, joyeuses, gaies, euphoriques), tandis que les chansons avec une valence basse semblent plus négatives (par exemple tristes, déprimées, en colère). Tempo : Le tempo global estimé d'une chanson en battements par minute (BPM). Dans la terminologie musicale, le tempo est la vitesse ou le rythme d'une pièce donnée et découle directement de la durée moyenne des temps. hit : Variable dichotomique mesurant si une chanson est hit ou non. Elle prend la valeur de 1 si la chanson est hit, 0 sinon. C'est notre variable dépendante, c'est-à-dire celle que l'on cherchera à prédire pour une chanson donnée. featuring : Variable dépendante dichotomique mesurant s'il y a un ou plusieurs artistes invités sur une chanson. mois : Mois de sortie de la chanson. jour_sem : Jour de la semaine durant lequel la chanson a été diffusée. jour : Jour de sortie de la chanson. Certaines de ces variables sont utilisées uniquement pour l'analyse, d'autres participent à toutes les étapes du pipeline. A présent, jetons un coup d'oeil sur la dimension de notre jeu de données. In [2]: df . shape Out[2]: (19182, 24) Après avoir choisi les variables disponibles jugées pertinentes pour le modèle, supprimé les observations contenant des valeurs manquantes et les duplications, notre jeu est réduit à 19 120 observations contenant 24 variables chacune. Les 5 premières observations de notre jeu sont les suivantes: In [3]: df . head ( n = 5 ) Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } nom_artiste pop_artiste tot_followers nom_chanson marche_disp date_sortie pop_chanson acoustique dansabilite duree ... eloquence tempo time_signature valence hit featuring search mois_sortie jour_sortie jour_sem_sortie 0 Kesha 81 5470072 TiK ToK 79 2010-01-01 79 0.09910 0.755 199693 ... 0.1420 120.028 4 0.714 1 0 Kesha TiK ToK 1 1 4 1 Lady Antebellum 74 2933375 Need You Now 78 2010-01-01 69 0.09270 0.587 277573 ... 0.0303 107.943 4 0.231 1 0 Lady Antebellum Need You Now 1 1 4 2 Train 77 3249275 Hey, Soul Sister 79 2010-12-01 82 0.18500 0.673 216773 ... 0.0431 97.012 4 0.795 1 0 Train Hey, Soul Sister 12 1 2 3 Katy Perry 87 15347727 California Gurls 79 2012-03-12 72 0.00446 0.791 234653 ... 0.0569 125.014 4 0.425 1 0 Katy Perry California Gurls 3 12 0 4 Usher 82 7654666 OMG (feat. will.i.am) 79 2010-03-30 71 0.19800 0.781 269493 ... 0.0332 129.998 4 0.326 1 1 Usher OMG (feat. will.i.am) 3 30 1 5 rows × 24 columns Visualisation In [4]: % matplotlib inline from matplotlib import pyplot as plt fig = plt . figure ( figsize = ( 16 , 8 )) ax = fig . add_axes ([ 0 , 0 , 1 , 1 ]) pop = [ 'non-hit' , 'hit' ] pop_count = list ( df [ 'hit' ] . value_counts ()) ax . bar ( pop , pop_count , color = '#293484' ) for i , v in enumerate ( pop_count ): ax . text ( i -. 05 , v + 100 , pop_count [ i ], fontsize = 12 , color = 'black' ) plt . title ( 'Distribution des nombres de chansons \\n suivant les modalités de la variable hit.' ) plt . ylabel ( 'nombre_de_chansons' ) plt . xlabel ( 'classe' ) plt . show () La distribution de la variable dépendante hit est telle que seulement 902 chansons du jeu de données sont hits, alors que 18280 ne le sont pas. Il y a lieu de contraster un déséquilibre flagrant au sein de notre variable d'intérêt. On règlera ce souci plus tard avant de passer à la phase d'entraînement de notre modèle. In [5]: fig ,( ax1 , ax2 , ax3 ) = plt . subplots ( 1 , 3 , figsize = ( 18 , 8 )) fig . suptitle ( 'Date de sortie des musiques hits' ) ax1 . set_title ( 'Mois' ) ax1 . hist ( df [ df [ 'hit' ] == 1 ][ 'mois_sortie' ], bins = 30 , color = 'blue' ) ax2 . set_title ( 'Jour de la semaine' ) ax2 . hist ( df [ df [ 'hit' ] == 1 ][ 'jour_sem_sortie' ], bins = 14 , color = 'red' ) ax3 . set_title ( 'Jour' ) ax3 . hist ( df [ df [ 'hit' ] == 1 ][ 'jour_sortie' ], bins = 62 , color = 'blue' ) plt . show () A la lumière du graphique ci-dessus, janvier est le mois durant lequel plus de musiques hits sont sorties; juillet étant le mois le moins sollicité. On remarque aussi que la majorité des hits de la période sont sortis le 4ème jour de la semaine; soit jeudi. Enfin le premier jour du mois est largement plus utilisé pour publier une chanson. Fort de ce constat, on pourrait déduire que publier une chanson le premier janvier, c'est probablement un pas vers l'optimisation des chances de sa viralité. On doit tout de même être prudent: corrélation n'est pas causalité. Il faudrait pousser notre analyse plus en profondeur afin d'être plus précis dans cette conclusion. Quels sont les artistes les plus populaires sur la période considérée? In [6]: plt . figure ( figsize = ( 16 , 8 )) artistes = df [ df [ 'hit' ] == 1 ][ 'nom_artiste' ] . value_counts ()[: 20 ] artistes . plot ( kind = \"bar\" , color = 'blue' ) plt . title ( \"Les artistes avec le plus de musiques hits\" ) plt . show () Sans surprise aucune, les artistes comme Drake, Rihanna et Taylor Swift ont enregistré plus de musiques hits que quiconque autre artiste sur la période. Ceci étant dit, il est plausible de croire qu'une chanson a plus de chances d'être virale si elle contient la voix de l'un de ces artistes. In [7]: plt . figure ( figsize = ( 16 , 8 )) plt . hist ( df [ df [ 'hit' ] == 1 ][ 'pop_artiste' ], bins = 100 , density = True , alpha = 0.5 , label = \"hit\" , color = 'blue' ) plt . hist ( df [ df [ 'hit' ] == 0 ][ 'pop_artiste' ], bins = 100 , density = True , alpha = 0.5 , label = \"non-hit\" , color = 'red' ) plt . title ( \"Popularité des artistes\" ) plt . legend () plt . show () Les deux distributions sont assymétriques à droite. Cependant, l'assymétrie de la distribution des musiques hits est plus prononcée. 75 % des musiques non-hits ont des artistes dont la popularité est inférieure à 82, alors que seulement la popularité des artistes de 50 % des musiques hits est inférieure à ce nombre. pop_artiste pourrait être une variable explicative importante dans la prédiction de la classe d'une chanson. Quid de la répartition des variables d'audio au sein des deux catégories? In [8]: import numpy as np from matplotlib import pyplot as plt features_hit = df . loc [ df [ 'hit' ] == 1 ,[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'eloquence' , 'valence' ]] features_non_hit = df . loc [ df [ 'hit' ] == 0 ,[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'eloquence' , 'valence' ]] N = len ( features_hit . mean ()) #Liste des nombre de variables ind = np . arange ( N ) width = 0.25 #diagrame en batons avec la liste des musiques hits plt . barh ( ind , features_hit . mean () , width , label = 'hits' , color = 'blue' ) #diagrame en batons avec la liste des musiques non hits plt . barh ( ind + width , features_non_hit . mean (), width , label = 'non-hits' , color = 'red' ) #X- label plt . xlabel ( 'Moyenne' , fontsize = 12 ) # Title plt . title ( \"Distribution des valeurs moyennes \\n des caractéristiques d'audio des chansons.\" ) #Vertical ticks plt . yticks ( ind + width / 2 , ( list ( features_non_hit )[:]), fontsize = 12 ) #legend plt . legend ( loc = 'best' ) # Figure size plt . rcParams [ 'figure.figsize' ] = ( 16 , 8 ) # Set style plt . style . use ( \"ggplot\" ) plt . show () Les variables prédominantes au sein des deux catégories sont les mêmes : energie , dansabilite et valence . La seule différence est que les valeurs moyennées de ces variables sont plus élevées pour la catégorie des chansons hits. Ceci atteste que les musiques hits sont plus rapides et sonores. Elles sont plus adaptées à la danse et sont plus enclines à inspirer la joie, la gaité, l'euphorie. L'approche de machine learning Jusque-là, nous avons pu découvrir quelques insights interéssants à propos des données. Afin d'écourter cet article, passons directement à la partie concernant l'algorithme de machine learning que nous allons utiliser. Nous allons construire un modèle afin de prédire la classe, hit ou non-hit, qu'une musique est la plus susceptible d'appartenir en nous basant sur un ensemble de variables explicatives, comme expliqué au début de cet article. Il est important de garder en tête que nous voulons un modèle qui soit le plus performant possible. Nous allons utiliser l'algorithme de classification de LightGBM . Pourquoi? [J'ai découvert ce framework récemment alors que je participais à une compétition sur Kaggle.] LightGBM fournit des résultats robustes et il est largement utilisé dans de nombreuses solutions gagnantes de concours de machine learning. En guise d'expliquer comment l'algorithme fonctionne, nous nous contenterons de mentionner que nous allons utiliser une approche de machine learning supervisé et que LightGBM est un framework de gradient boosting qui utilise des algorithmes d'apprentissage basés sur des arbres. Il est conçu pour être distribué et efficient avec les avantages suivants: Vitesse d'entraînement plus rapide et efficacité plus élevée. Utilisation réduite de la mémoire. Meilleure précision. Prise en charge de l'apprentissage parallèle et GPU. Capable de gérer des données à grande échelle. Suppression de variables La première étape dans la préparation de notre jeu de données pour l'entrainement du modèle est de nous assurer que toutes les colonnes sont de valeurs numériques. C'est en ce sens que nous avons supprimé les variables comme nom_chanson, search, nom_artiste, date_sortie, jour_sortie, jour_sem_sortie et mois_sortie. In [9]: df . drop ([ 'nom_chanson' , 'search' , 'nom_artiste' , 'date_sortie' , 'jour_sem_sortie' , 'jour_sortie' , 'mois_sortie' , 'time_signature' ], axis = 1 , inplace = True ) Feature engineering A ce stade, nous avons eu recours à plusieurs techniques afin d'optimiser notre jeu de données. En réalité, nous en avons déjà appliqué quelques-unes au début lorsqu'il était question de gérer les valeurs manquantes, les duplications, l'extraction des dates, One-Hot-Encoding, etc. A présent nous allons appliquer la technique dite scaling sur quelques variables du jeu. Cette technique a la vertu de mettre toutes les variables numériques quantitatives sur une même base comparable. Bien, voyons à quoi ressemble notre jeu maintenant. In [10]: from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler () df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'duree' , 'pop_chanson' ]] = scaler . fit_transform ( df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'duree' , 'pop_chanson' ]]) In [11]: df . head ( n = 2 ) Out[11]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } pop_artiste tot_followers marche_disp pop_chanson acoustique dansabilite duree energie instrumentalite vivacite intensite eloquence tempo valence hit featuring 0 0.81 0.084919 1.000000 0.822917 0.099498 0.771195 0.031525 0.836997 0.000000 0.291919 0.933029 0.149474 0.545336 0.721212 1 0 1 0.74 0.045538 0.987179 0.718750 0.093072 0.599591 0.046020 0.621992 0.000636 0.202020 0.882599 0.031895 0.490429 0.233333 1 0 Veuillez remarquer que toutes les variables quantitatives indépendantes sont comprises dans l'intervalle [0,1]. Dans la réalité, cela ne fait aucun sens qu'une variable telle que tot_followers , par exemple, contienne des valeurs entre 0 et 1. Mais du point de vue de l'algorithme, cela a tout son sens car c'est par ce procédé que les variables deviennent comparables. Les algorithmes de machine learning fonctionnent mieux lorsque les variables indépendantes sont relativement à une échelle similaire et proches de la distribution normale. Suréchantillonage des données Rappelons-nous qu'au regard de la variable dépendante, notre jeu de données est très déséquilibré. La catégorie hit est sous-représentée par rapport à la classe non-hit. Pour y remédier, nous allons recourir à la technique dite SMOTE. SMOTE (Synthetic Minority Over-Sampling TEchnique) est une technique utilisée pour traiter des ensembles de données déséquilibrées. Introduite pour la première fois par Nitesh V. Chawla, SMOTE est une technique basée sur les plus proches voisins avec une distance euclidienne entre les points de données dans l'espace des caractéristiques. In [12]: from imblearn.over_sampling import SMOTE sm = SMOTE ( random_state = 42 ) X = df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'duree' ]] y = df [ 'hit' ] X_res , y_res = sm . fit_resample ( X , y ) # Visualisation du changement y_res . value_counts () Out[12]: 1 18280 0 18280 Name: hit, dtype: int64 On remarque que les deux classes ont bien le même nombre d'observations. L'entrainement du modèle se fera donc sur des données équilibrées. Le critère de performance dont on se servira pour l'évaluer est bien accuracy . Modèle Tout est fin prêt pour entraîner et évaluer notre modèle. In [13]: import lightgbm as lgb from sklearn.model_selection import train_test_split from sklearn.metrics import auc , accuracy_score , roc_auc_score , roc_curve , confusion_matrix % matplotlib inline import seaborn as sns import matplotlib.pyplot as plt # Fractionnement du dataset en deux sous-jeux: un pour l'entrainement et l'autre pour tester X_train , X_test , y_train , y_test = train_test_split ( X_res , y_res , test_size = 0.30 , random_state = 20 ) # Paramètres optimisés via GridSearch clf = lgb . LGBMClassifier ( boosting_type = 'gbdt' , class_weight = None , colsample_bytree = 1.0 , importance_type = 'split' , learning_rate = 0.2 , max_depth =- 1 , min_child_samples = 20 , min_child_weight = 0.001 , min_split_gain = 0.0 , n_estimators = 100 , n_jobs =- 1 , num_leaves = 31 , objective = None , random_state = None , reg_alpha = 0.0 , reg_lambda = 0.0 , silent = True , subsample = 1.0 , subsample_for_bin = 200000 , subsample_freq = 0 ) clf . fit ( X_train , y_train ) # évaluation de la performance du modèle y_pred = clf . predict ( X_test ) accuracy = accuracy_score ( y_pred , y_test ) print ( 'Score de précision du modèle : {0:0.4f} ' . format ( accuracy )) Score de précision du modèle : 0.8973 La précision du modèle atteint les 89 %, ce qui est très bien. La visualisation de la matrice de confusion nous permet de comprendre les erreurs commises par notre modèle-classeur par rapport au sous-jeu de test. In [14]: cm = confusion_matrix ( y_test , y_pred ) mc_matrice = pd . DataFrame ( data = cm , columns = [ 'Classe réelle:0' , 'Classe réelle:1' ], index = [ 'Classe prédite:0' , 'Classe prédite:1' ]) plt . figure ( figsize = ( 16 , 8 )) ax1 = plt . axes () sns . heatmap ( mc_matrice , ax = ax1 , annot = True , fmt = 'd' , cmap = 'BuPu' ) ax1 . set_title ( 'Matrice de confusion' ) plt . show () La matrice de confusion est une matrice qui mesure la qualité d'un système de classification. Le diagonal principal représente les observations classées correctement par le modèle, et le diagonal secondaire, celles classées incorrectement. De ce fait, l'erreur la plus fréquente commise par le modèle est d'avoir classé une chanson en tant que non-hit alors qu'en réalité elle était hit (837 cas), l'erreur de type II plus précisément. L'erreur de type I consiste en ce que le modèle classe une musique comme hit alors qu'elle est non-hit; et l'erreur de type II, l'inverse; c'est-à-dire le cas où il classe une musique comme non-hit pourtant elle est hit. Si nous essayons de comprendre la psychologie d'un producteur de musiques, l'erreur de type I est moins acceptable que celle de type II. On ne voudrait pas consentir toutes les dépenses liées à la production et la promotion d'une musique qu'un modèle a prédit 'hit' pour que finalement elle ne le soit pas. La valeur de l'erreur de type I devrait être minimale. De manière générale, le modèle devrait être plus performant. Nous pouvons comprendre à présent les variables explicatives ayant le plus de poids dans le processus de classification de notre variable dépendante en visualisant le graphique d'importance. In [15]: ax = lgb . plot_importance ( clf , height = 0.4 , max_num_features = 10 , importance_type = 'split' , xlim = ( 0 , 500 ), ylim = ( 0 , 10 ), color = 'b' , figsize = ( 16 , 8 )) plt . show () Le graphique d'importance permet la visualisation des variables indépendantes les plus utiles, dans la prédiction de la variable d'intérêt, par ordre décroissant. Tempo est la variable explicative la plus importante du modèle pour la prédiction de la variable hit . Ensuite, les variables explicatives les plus pertinentes sont l' acoustique et la valence , et enfin viennent les autres variables relatives à l'audio. Plus de données, meilleur modèle Après ajout d'autres variables relatives à l'artiste et à la chanson telles que pop_artiste , tot_followers , marche_disp et pop_chanson dans le modèle, la précision de ce dernier atteint les 98 %, ce qui est excellent comme niveau de performance. Cela signifie que notre modèle a la capacité de prédire si une musique va être hit ou non-hit, seulement en se basant sur ces variables de manière générale, avec plus de 98% de chances que la prédiction soit correcte. In [16]: X = df [[ 'acoustique' , 'dansabilite' , 'energie' , 'instrumentalite' , 'vivacite' , 'intensite' , 'eloquence' , 'valence' , 'tempo' , 'duree' , 'featuring' , 'pop_artiste' , 'tot_followers' , 'marche_disp' , 'pop_chanson' ]] y = df [ 'hit' ] X_res , y_res = sm . fit_resample ( X , y ) X_train , X_test , y_train , y_test = train_test_split ( X_res , y_res , test_size = 0.30 , random_state = 20 ) clf . fit ( X_train , y_train ) y_pred = clf . predict ( X_test ) accuracy = accuracy_score ( y_pred , y_test ) print ( 'Score de précision du modèle: {0:0.4f} ' . format ( accuracy )) Score de précision du modèle: 0.9806 Matrice de confusion In [17]: cm = confusion_matrix ( y_test , y_pred ) mc_matrice = pd . DataFrame ( data = cm , columns = [ 'Classe réelle:0' , 'Classe réelle:1' ], index = [ 'Classe prédite:0' , 'Classe prédite:1' ]) plt . figure ( figsize = ( 16 , 8 )) ax2 = plt . axes () sns . heatmap ( mc_matrice , ax = ax2 , annot = True , fmt = 'd' , cmap = 'BuPu' ) ax2 . set_title ( 'Matrice de confusion' ) plt . show () Les erreurs de type I et II sont passées respectivement de 289 à 111 et de 837 à 102 cas. Elles sont toutes deux diminuées et proches. Cela témoigne du niveau, très proche et faible, de probabilité pour le modèle de classer incorrectement une chanson. Visualisons à présent le nouveau graphique d'importance. In [18]: ax = lgb . plot_importance ( clf , height = 0.4 , max_num_features = 18 , importance_type = 'split' , xlim = ( 0 , 600 ), ylim = ( 0 , 16 ), color = 'r' , figsize = ( 16 , 8 )) plt . show () Les nouvelles variables augmentent la performance globale du modèle considérablement, qui est passée de 89 à 98 %. Elles sont les principales variables indépendantes dans la détermination de la classe d'une chanson. Ensuite, viennent les autres variables liées à l'audio par ordre d'importance. Conclusion Dans cette première partie de l'article, nous avons construit un modèle pouvant classer une chanson en hit ou non-hit suivant des variables lui étant propres. Pour y parvenir, nous avons utilisé Billboard et Spotify pour construire notre jeu de données. Une brève visualisation des données a été effectuée avant d'entraîner le modèle. Nous avons mis en application les techniques de « feature engineering » afin de normaliser les données. La technique SMOTE nous a été utile afin d'assurer la gestion de nos données qui, au regard des modalités de notre variable dépendante « hit », étaient déséquilibrées, . Après avoir entraîné et évalué le modèle uniquement avec les données liées aux caractéristiques d'audio des musiques, une précision de 86 % a été obtenue; et, après ajout d'autres variables liées au profil de l'artiste dans le modèle, la précision a atteint les 98 %. De notre analyse il faut retenir ceci: essentiellement, une musique est « hit » si elle est populaire sur Spotify, est interpretée par un artiste lui-même populaire sur Spotify et possède un nombre important de followers, et enfin, si elle est disponible dans le plus grand nombre de pays à travers le monde. Cette conclusion semble logique, mais elle est aussi vérifiée empiriquement par notre modèle. Généralement, une musique possède une autre caractéristique importante que nous n'avons pas encore prise en compte: les paroles. Pouvons-nous augmenter davantage la performance du modèle en nous servant des lyriques? C'est ce que nous allons explorer dans la deuxième partie de l'article. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Machine Learning","url":"https://jbobym.github.io/Prédiction_des_prochaines_musiques_hits_(partie_1)","loc":"https://jbobym.github.io/Prédiction_des_prochaines_musiques_hits_(partie_1)"}]};